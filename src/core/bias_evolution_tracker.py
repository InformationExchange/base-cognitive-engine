"""
BAIS Cognitive Governance Engine
Bias Evolution Tracker (PPA1-Inv1)

Tracks bias patterns over time, detects drift, and learns from feedback.
This is a CRITICAL missing implementation identified by BAIS governance.

Patent Reference: PPA1-Inv1 - Bias Evolution Tracking
"""

import logging
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from collections import deque
from enum import Enum
import numpy as np
import hashlib
import json

logger = logging.getLogger(__name__)


class BiasType(Enum):
    """Types of bias that can be tracked."""
    FACTUAL = "factual"
    BEHAVIORAL = "behavioral"
    TEMPORAL = "temporal"
    DEMOGRAPHIC = "demographic"
    CONFIRMATION = "confirmation"
    SELECTION = "selection"
    ANCHORING = "anchoring"
    AVAILABILITY = "availability"


class DriftType(Enum):
    """Types of drift detected."""
    NONE = "none"
    GRADUAL = "gradual"
    SUDDEN = "sudden"
    RECURRING = "recurring"
    SEASONAL = "seasonal"


class TrendDirection(Enum):
    """Direction of bias trend."""
    STABLE = "stable"
    INCREASING = "increasing"
    DECREASING = "decreasing"
    OSCILLATING = "oscillating"


@dataclass
class BiasSnapshot:
    """Point-in-time bias measurement."""
    timestamp: datetime
    domain: str
    bias_type: BiasType
    score: float  # 0.0 (no bias) to 1.0 (severe bias)
    confidence: float
    context_features: Dict[str, float] = field(default_factory=dict)
    evidence: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'timestamp': self.timestamp.isoformat(),
            'domain': self.domain,
            'bias_type': self.bias_type.value,
            'score': self.score,
            'confidence': self.confidence,
            'context_features': self.context_features,
            'evidence': self.evidence
        }


@dataclass
class BiasEvolution:
    """Evolution of bias over a time period."""
    domain: str
    bias_type: BiasType
    start_time: datetime
    end_time: datetime
    snapshots: List[BiasSnapshot]
    trend: TrendDirection
    drift_detected: bool
    drift_type: DriftType
    average_score: float
    variance: float
    peak_score: float
    peak_time: Optional[datetime]
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'domain': self.domain,
            'bias_type': self.bias_type.value,
            'start_time': self.start_time.isoformat(),
            'end_time': self.end_time.isoformat(),
            'snapshot_count': len(self.snapshots),
            'trend': self.trend.value,
            'drift_detected': self.drift_detected,
            'drift_type': self.drift_type.value,
            'average_score': self.average_score,
            'variance': self.variance,
            'peak_score': self.peak_score,
            'peak_time': self.peak_time.isoformat() if self.peak_time else None
        }


@dataclass
class DriftResult:
    """Result of drift detection."""
    detected: bool
    drift_type: DriftType
    severity: float  # 0.0 to 1.0
    confidence: float
    change_point: Optional[datetime]
    baseline_score: float
    current_score: float
    statistical_significance: float
    recommendation: str
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'detected': self.detected,
            'drift_type': self.drift_type.value,
            'severity': self.severity,
            'confidence': self.confidence,
            'change_point': self.change_point.isoformat() if self.change_point else None,
            'baseline_score': self.baseline_score,
            'current_score': self.current_score,
            'statistical_significance': self.statistical_significance,
            'recommendation': self.recommendation
        }


@dataclass
class LearningFeedback:
    """Feedback for learning."""
    snapshot_id: str
    was_correct: bool
    actual_bias_present: bool
    actual_severity: Optional[float]
    feedback_source: str  # 'human', 'automated', 'consensus'
    timestamp: datetime = field(default_factory=datetime.utcnow)


class BiasEvolutionTracker:
    """
    Tracks bias evolution over time with learning capabilities.
    
    PPA1-Inv1: Bias Evolution Tracking
    
    Features:
    - Time-series tracking of bias scores
    - Statistical drift detection (Page-Hinkley, CUSUM)
    - Trend analysis (increasing, decreasing, oscillating)
    - Learning from feedback
    - Domain-specific bias profiles
    - Adaptive thresholds
    """
    
    def __init__(
        self,
        window_size: int = 100,
        drift_threshold: float = 0.15,
        min_samples_for_drift: int = 20,
        learning_rate: float = 0.1
    ):
        """
        Initialize the bias evolution tracker.
        
        Args:
            window_size: Number of snapshots to retain per domain/type
            drift_threshold: Threshold for drift detection
            min_samples_for_drift: Minimum samples before drift detection
            learning_rate: Learning rate for adaptive updates
        """
        self.window_size = window_size
        self.drift_threshold = drift_threshold
        self.min_samples_for_drift = min_samples_for_drift
        self.learning_rate = learning_rate
        
        # Storage: domain -> bias_type -> deque of snapshots
        self._snapshots: Dict[str, Dict[BiasType, deque]] = {}
        
        # Learned thresholds per domain
        self._domain_thresholds: Dict[str, Dict[BiasType, float]] = {}
        
        # Baseline statistics for drift detection
        self._baselines: Dict[str, Dict[BiasType, Dict[str, float]]] = {}
        
        # Learning history
        self._feedback_history: List[LearningFeedback] = []
        self._learning_outcomes: Dict[str, List[Tuple[float, bool]]] = {}
        
        # CUSUM statistics for drift detection
        self._cusum_pos: Dict[str, Dict[BiasType, float]] = {}
        self._cusum_neg: Dict[str, Dict[BiasType, float]] = {}
        
        # Performance tracking
        self._true_positives = 0
        self._false_positives = 0
        self._true_negatives = 0
        self._false_negatives = 0
        
        logger.info("[BiasEvolutionTracker] Initialized with learning capabilities")
    
    def _get_snapshot_key(self, snapshot: BiasSnapshot) -> str:
        """Generate unique key for a snapshot."""
        content = f"{snapshot.timestamp.isoformat()}_{snapshot.domain}_{snapshot.bias_type.value}_{snapshot.score}"
        return hashlib.md5(content.encode()).hexdigest()[:12]
    
    def _ensure_storage(self, domain: str, bias_type: BiasType):
        """Ensure storage structures exist for domain/type."""
        if domain not in self._snapshots:
            self._snapshots[domain] = {}
            self._domain_thresholds[domain] = {}
            self._baselines[domain] = {}
            self._cusum_pos[domain] = {}
            self._cusum_neg[domain] = {}
        
        if bias_type not in self._snapshots[domain]:
            self._snapshots[domain][bias_type] = deque(maxlen=self.window_size)
            self._domain_thresholds[domain][bias_type] = self.drift_threshold
            self._baselines[domain][bias_type] = {'mean': 0.5, 'std': 0.1, 'count': 0}
            self._cusum_pos[domain][bias_type] = 0.0
            self._cusum_neg[domain][bias_type] = 0.0
    
    def track_bias(
        self,
        response: str,
        domain: str,
        bias_type: BiasType = BiasType.BEHAVIORAL,
        score: Optional[float] = None,
        confidence: float = 0.8,
        context_features: Optional[Dict[str, float]] = None,
        evidence: Optional[List[str]] = None
    ) -> BiasSnapshot:
        """
        Track a bias measurement.
        
        Args:
            response: The response being analyzed
            domain: Domain context (e.g., 'medical', 'financial')
            bias_type: Type of bias being measured
            score: Bias score (0-1), or None to auto-detect
            confidence: Confidence in the measurement
            context_features: Additional context features
            evidence: Evidence for the bias score
            
        Returns:
            BiasSnapshot of the measurement
        """
        self._ensure_storage(domain, bias_type)
        
        # Auto-detect score if not provided
        if score is None:
            score = self._detect_bias_score(response, domain, bias_type)
        
        snapshot = BiasSnapshot(
            timestamp=datetime.utcnow(),
            domain=domain,
            bias_type=bias_type,
            score=score,
            confidence=confidence,
            context_features=context_features or {},
            evidence=evidence or []
        )
        
        # Add to storage
        self._snapshots[domain][bias_type].append(snapshot)
        
        # Update baseline statistics
        self._update_baseline(domain, bias_type, score)
        
        # Update CUSUM for drift detection
        self._update_cusum(domain, bias_type, score)
        
        logger.debug(f"[BiasEvolutionTracker] Tracked {bias_type.value} bias in {domain}: {score:.3f}")
        
        return snapshot
    
    def _detect_bias_score(self, response: str, domain: str, bias_type: BiasType) -> float:
        """
        Auto-detect bias score from response.
        
        This is a simplified implementation - production would use ML models.
        """
        score = 0.0
        response_lower = response.lower()
        
        # Behavioral bias indicators
        behavioral_patterns = [
            ('always', 0.1), ('never', 0.1), ('all', 0.08),
            ('everyone', 0.08), ('nobody', 0.08), ('must', 0.05),
            ('should', 0.03), ('obviously', 0.05), ('clearly', 0.03)
        ]
        
        for pattern, weight in behavioral_patterns:
            if pattern in response_lower:
                score += weight
        
        # Domain-specific adjustments
        if domain == 'medical' and any(word in response_lower for word in ['cure', 'guaranteed', 'always works']):
            score += 0.2
        elif domain == 'financial' and any(word in response_lower for word in ['guaranteed returns', 'risk-free', 'always profitable']):
            score += 0.2
        
        # Apply learned threshold adjustment
        if domain in self._domain_thresholds and bias_type in self._domain_thresholds[domain]:
            threshold_adjustment = self._domain_thresholds[domain][bias_type] - self.drift_threshold
            score = max(0.0, min(1.0, score - threshold_adjustment * 0.1))
        
        return min(1.0, score)
    
    def _update_baseline(self, domain: str, bias_type: BiasType, score: float):
        """Update baseline statistics with new score."""
        baseline = self._baselines[domain][bias_type]
        n = baseline['count']
        old_mean = baseline['mean']
        
        # Welford's online algorithm for mean and variance
        n += 1
        delta = score - old_mean
        new_mean = old_mean + delta / n
        
        if n > 1:
            old_std = baseline['std']
            # Approximate variance update
            new_var = ((n - 2) * old_std**2 + delta * (score - new_mean)) / (n - 1)
            baseline['std'] = np.sqrt(max(0, new_var))
        
        baseline['mean'] = new_mean
        baseline['count'] = n
    
    def _update_cusum(self, domain: str, bias_type: BiasType, score: float):
        """Update CUSUM statistics for drift detection."""
        baseline = self._baselines[domain][bias_type]
        threshold = self._domain_thresholds[domain][bias_type]
        
        # CUSUM update
        deviation = score - baseline['mean']
        k = threshold / 2  # Slack parameter
        
        self._cusum_pos[domain][bias_type] = max(0, self._cusum_pos[domain][bias_type] + deviation - k)
        self._cusum_neg[domain][bias_type] = max(0, self._cusum_neg[domain][bias_type] - deviation - k)
    
    def get_evolution(
        self,
        domain: str,
        bias_type: Optional[BiasType] = None,
        time_range: Optional[timedelta] = None
    ) -> List[BiasEvolution]:
        """
        Get bias evolution for a domain.
        
        Args:
            domain: Domain to analyze
            bias_type: Specific bias type, or None for all
            time_range: Time range to analyze, or None for all
            
        Returns:
            List of BiasEvolution results
        """
        if domain not in self._snapshots:
            return []
        
        results = []
        bias_types = [bias_type] if bias_type else list(self._snapshots[domain].keys())
        
        for bt in bias_types:
            if bt not in self._snapshots[domain]:
                continue
            
            snapshots = list(self._snapshots[domain][bt])
            
            # Filter by time range
            if time_range and snapshots:
                cutoff = datetime.utcnow() - time_range
                snapshots = [s for s in snapshots if s.timestamp >= cutoff]
            
            if not snapshots:
                continue
            
            # Calculate statistics
            scores = [s.score for s in snapshots]
            avg_score = np.mean(scores)
            variance = np.var(scores) if len(scores) > 1 else 0.0
            peak_score = max(scores)
            peak_idx = scores.index(peak_score)
            peak_time = snapshots[peak_idx].timestamp
            
            # Detect trend
            trend = self._detect_trend(scores)
            
            # Detect drift
            drift_result = self.detect_drift(domain, bt)
            
            evolution = BiasEvolution(
                domain=domain,
                bias_type=bt,
                start_time=snapshots[0].timestamp,
                end_time=snapshots[-1].timestamp,
                snapshots=snapshots,
                trend=trend,
                drift_detected=drift_result.detected,
                drift_type=drift_result.drift_type,
                average_score=avg_score,
                variance=variance,
                peak_score=peak_score,
                peak_time=peak_time
            )
            results.append(evolution)
        
        return results
    
    def _detect_trend(self, scores: List[float]) -> TrendDirection:
        """Detect trend direction in scores."""
        if len(scores) < 3:
            return TrendDirection.STABLE
        
        # Simple linear regression
        x = np.arange(len(scores))
        slope = np.polyfit(x, scores, 1)[0]
        
        # Check for oscillation
        sign_changes = sum(1 for i in range(1, len(scores)) if (scores[i] - scores[i-1]) * (scores[i-1] - scores[i-2] if i > 1 else 1) < 0)
        oscillation_ratio = sign_changes / (len(scores) - 1)
        
        if oscillation_ratio > 0.6:
            return TrendDirection.OSCILLATING
        elif slope > 0.01:
            return TrendDirection.INCREASING
        elif slope < -0.01:
            return TrendDirection.DECREASING
        else:
            return TrendDirection.STABLE
    
    def detect_drift(
        self,
        domain: str,
        bias_type: Optional[BiasType] = None
    ) -> DriftResult:
        """
        Detect drift in bias patterns.
        
        Args:
            domain: Domain to check
            bias_type: Specific type or None for aggregate
            
        Returns:
            DriftResult with detection details
        """
        if domain not in self._snapshots:
            return DriftResult(
                detected=False,
                drift_type=DriftType.NONE,
                severity=0.0,
                confidence=0.0,
                change_point=None,
                baseline_score=0.5,
                current_score=0.5,
                statistical_significance=0.0,
                recommendation="No data available for drift detection"
            )
        
        # Aggregate across bias types if none specified
        if bias_type is None:
            all_cusum_pos = sum(self._cusum_pos[domain].values())
            all_cusum_neg = sum(self._cusum_neg[domain].values())
            baseline_mean = np.mean([b['mean'] for b in self._baselines[domain].values()])
            all_snapshots = []
            for bt in self._snapshots[domain].values():
                all_snapshots.extend(bt)
        else:
            if bias_type not in self._snapshots[domain]:
                return DriftResult(
                    detected=False,
                    drift_type=DriftType.NONE,
                    severity=0.0,
                    confidence=0.0,
                    change_point=None,
                    baseline_score=0.5,
                    current_score=0.5,
                    statistical_significance=0.0,
                    recommendation=f"No data for {bias_type.value}"
                )
            
            all_cusum_pos = self._cusum_pos[domain][bias_type]
            all_cusum_neg = self._cusum_neg[domain][bias_type]
            baseline_mean = self._baselines[domain][bias_type]['mean']
            all_snapshots = list(self._snapshots[domain][bias_type])
        
        if len(all_snapshots) < self.min_samples_for_drift:
            return DriftResult(
                detected=False,
                drift_type=DriftType.NONE,
                severity=0.0,
                confidence=0.0,
                change_point=None,
                baseline_score=baseline_mean,
                current_score=baseline_mean,
                statistical_significance=0.0,
                recommendation=f"Need {self.min_samples_for_drift} samples, have {len(all_snapshots)}"
            )
        
        # Calculate current score (recent window)
        recent_scores = [s.score for s in sorted(all_snapshots, key=lambda x: x.timestamp)[-10:]]
        current_score = np.mean(recent_scores)
        
        # CUSUM threshold
        h = self.drift_threshold * 5  # Decision boundary
        
        detected = all_cusum_pos > h or all_cusum_neg > h
        cusum_max = max(all_cusum_pos, all_cusum_neg)
        severity = min(1.0, cusum_max / (h * 2))
        
        # Determine drift type
        if not detected:
            drift_type = DriftType.NONE
        elif cusum_max > h * 3:
            drift_type = DriftType.SUDDEN
        else:
            drift_type = DriftType.GRADUAL
        
        # Statistical significance (simplified)
        significance = min(1.0, cusum_max / h) if h > 0 else 0.0
        
        # Find change point (simplified - find max deviation point)
        change_point = None
        if detected and all_snapshots:
            deviations = [(s, abs(s.score - baseline_mean)) for s in all_snapshots]
            max_deviation = max(deviations, key=lambda x: x[1])
            if max_deviation[1] > self.drift_threshold:
                change_point = max_deviation[0].timestamp
        
        # Generate recommendation
        if not detected:
            recommendation = "No significant drift detected. Continue monitoring."
        elif drift_type == DriftType.SUDDEN:
            recommendation = "ALERT: Sudden drift detected. Investigate recent changes immediately."
        else:
            recommendation = "Gradual drift detected. Review recent patterns and consider threshold adjustment."
        
        return DriftResult(
            detected=detected,
            drift_type=drift_type,
            severity=severity,
            confidence=0.8 if len(all_snapshots) > 50 else 0.6,
            change_point=change_point,
            baseline_score=baseline_mean,
            current_score=current_score,
            statistical_significance=significance,
            recommendation=recommendation
        )
    
    def learn_from_feedback(self, feedback: LearningFeedback):
        """
        Learn from feedback on bias detection accuracy.
        
        Args:
            feedback: Feedback on a previous detection
        """
        getattr(self, '_feedback_history', {}).append(feedback)
        
        # Update performance metrics
        if feedback.get('was_correct', True) and feedback.get('actual_bias_present', False):
            self._true_positives += 1
        elif feedback.get('was_correct', True) and not feedback.get('actual_bias_present', False):
            self._true_negatives += 1
        elif not feedback.get('was_correct', True) and feedback.get('actual_bias_present', False):
            self._false_negatives += 1
        else:
            self._false_positives += 1
        
        # Adaptive threshold adjustment
        if feedback.get('actual_severity', None) is not None:
            # Find the relevant domain/type from snapshot_id
            # For now, apply globally
            if not feedback.get('was_correct', True):
                if feedback.get('actual_bias_present', False):
                    # We missed it - lower thresholds
                    self._adjust_thresholds(-self.learning_rate * 0.1)
                else:
                    # False positive - raise thresholds
                    self._adjust_thresholds(self.learning_rate * 0.1)
        
        logger.info(f"[BiasEvolutionTracker] Learned from feedback: correct={feedback.get('was_correct', True)}")
    
    def _adjust_thresholds(self, adjustment: float):
        """Adjust all thresholds by a factor."""
        for domain in self._domain_thresholds:
            for bias_type in self._domain_thresholds[domain]:
                new_threshold = self._domain_thresholds[domain][bias_type] + adjustment
                self._domain_thresholds[domain][bias_type] = max(0.05, min(0.5, new_threshold))
    
    
    def record_outcome_standard(self, outcome: Dict) -> None:
        """Standard learning interface wrapper."""
        if not hasattr(self, '_outcomes'):
            self._outcomes = []
        self._outcomes.append(outcome)

    def record_outcome(self, outcome: Any) -> Dict[str, float]:
        """
        Record learning outcome (interface for LearningAlgorithm compatibility).
        
        Args:
            outcome: Learning outcome with domain, was_correct, etc.
            
        Returns:
            Updated threshold values
        """
        # Extract relevant info and create feedback
        if hasattr(outcome, 'domain') and hasattr(outcome, 'was_correct'):
            feedback = LearningFeedback(
                snapshot_id="auto",
                was_correct=outcome.was_correct,
                actual_bias_present=not outcome.was_correct,  # Assume if incorrect, bias was present
                actual_severity=None,
                feedback_source='automated'
            )
            self.learn_from_feedback(feedback)
        
        return self.get_statistics()
    
    def get_statistics(self) -> Dict[str, Any]:
        """Get tracker statistics."""
        total = self._true_positives + self._false_positives + self._true_negatives + self._false_negatives
        
        precision = self._true_positives / (self._true_positives + self._false_positives) if (self._true_positives + self._false_positives) > 0 else 0
        recall = self._true_positives / (self._true_positives + self._false_negatives) if (self._true_positives + self._false_negatives) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        
        return {
            'total_snapshots': sum(
                len(bt) for domain in getattr(self, '_snapshots', {}).values() for bt in domain.values()
            ),
            'domains_tracked': len(self._snapshots),
            'feedback_received': len(self._feedback_history),
            'true_positives': getattr(self, '_true_positives', 0),
            'false_positives': getattr(self, '_false_positives', 0),
            'true_negatives': getattr(self, '_true_negatives', 0),
            'false_negatives': getattr(self, '_false_negatives', 0),
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'domain_thresholds': {
                d: {bt.value: t for bt, t in bts.items()}
                for d, bts in getattr(self, '_domain_thresholds', {}).items()
            }
        }
    
    def get_state(self) -> Dict[str, Any]:
        """Get serializable state for persistence."""
        return {
            'window_size': self.window_size,
            'drift_threshold': self.drift_threshold,
            'min_samples_for_drift': self.min_samples_for_drift,
            'learning_rate': self.learning_rate,
            'domain_thresholds': {
                d: {bt.value: t for bt, t in bts.items()}
                for d, bts in getattr(self, '_domain_thresholds', {}).items()
            },
            'baselines': {
                d: {bt.value: b for bt, b in bls.items()}
                for d, bls in getattr(self, '_baselines', {}).items()
            },
            'statistics': self.get_statistics()
        }
    
    def load_state(self, state: Dict[str, Any]):
        """Load state from persistence."""
        self.window_size = state.get('window_size', self.window_size)
        self.drift_threshold = state.get('drift_threshold', self.drift_threshold)
        self.min_samples_for_drift = state.get('min_samples_for_drift', self.min_samples_for_drift)
        self.learning_rate = state.get('learning_rate', self.learning_rate)
        
        # Restore thresholds
        for domain, bts in state.get('domain_thresholds', {}).items():
            if domain not in self._domain_thresholds:
                self._domain_thresholds[domain] = {}
            for bt_str, threshold in bts.items():
                bt = BiasType(bt_str)
                self._domain_thresholds[domain][bt] = threshold
        
        logger.info("[BiasEvolutionTracker] State loaded")
    
    # ========================================
    # LEARNING INTERFACE (Auto-added)
    # ========================================
    
    def record_feedback(self, result, was_accurate):
        """Record feedback for learning adjustment."""
        self.record_outcome({'result': str(result)}, {}, was_accurate)
    
    def adapt_thresholds(self, threshold_name, current_value, direction='decrease'):
        """Adapt thresholds based on learning history."""
        adjustment = 0.05 if direction == 'increase' else -0.05
        return max(0.1, min(0.95, current_value + adjustment))
    
    def get_domain_adjustment(self, domain):
        """Get learned adjustment for a domain."""
        if not hasattr(self, '_domain_adjustments'):
            self._domain_adjustments = {}
        return getattr(self, '_domain_adjustments', {}).get(domain, 0.0)
    
    def get_learning_statistics(self):
        """Get learning statistics."""
        outcomes = getattr(self, '_outcomes', [])
        correct = sum(1 for o in outcomes if o.get('correct', False))
        return {
            'module': self.__class__.__name__,
            'total_outcomes': len(outcomes),
            'accuracy': correct / len(outcomes) if outcomes else 0.0
        }



    def serialize_state(self) -> Dict:
        """Serialize state for persistence."""
        return {
            'outcomes': getattr(self, '_outcomes', [])[-100:],
            'learning_params': getattr(self, '_learning_params', {}),
            'version': '1.0'
        }
    
    def deserialize_state(self, state: Dict) -> None:
        """Restore state from serialized data."""
        self._outcomes = state.get('outcomes', [])
        self._learning_params = state.get('learning_params', {})


if __name__ == "__main__":
    # Test the implementation
    tracker = BiasEvolutionTracker()
    
    # Track some bias
    for i in range(25):
        score = 0.3 + (i * 0.02) + np.random.normal(0, 0.05)
        snapshot = tracker.track_bias(
            response=f"Test response {i}",
            domain="medical",
            bias_type=BiasType.BEHAVIORAL,
            score=score,
            confidence=0.8
        )
    
    # Get evolution
    evolution = tracker.get_evolution("medical", BiasType.BEHAVIORAL)
    print(f"\nEvolution results: {len(evolution)}")
    if evolution:
        print(f"  Trend: {evolution[0].trend.value}")
        print(f"  Average score: {evolution[0].average_score:.3f}")
        print(f"  Drift detected: {evolution[0].drift_detected}")
    
    # Detect drift
    drift = tracker.detect_drift("medical", BiasType.BEHAVIORAL)
    print(f"\nDrift detection:")
    print(f"  Detected: {drift.detected}")
    print(f"  Type: {drift.drift_type.value}")
    print(f"  Severity: {drift.severity:.3f}")
    
    # Get statistics
    stats = tracker.get_statistics()
    print(f"\nStatistics:")
    print(f"  Total snapshots: {stats['total_snapshots']}")
    print(f"  Domains tracked: {stats['domains_tracked']}")
    
    print("\nâœ“ BiasEvolutionTracker implementation verified")


